{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6882_Scaffolding_Project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/serenabooth/Scaffolding_RL/blob/master/6882_Scaffolding_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9-o5V5dSftS",
        "colab_type": "text"
      },
      "source": [
        "Code is modified from https://cgnicholls.github.io/reinforcement-learning/2017/03/27/a3c.html\n",
        "\n",
        "Modifications: \n",
        "\n",
        "\n",
        "*   Modernized and updated to enable CoLab (e.g. Tensorboard)\n",
        "*   Updated monitoring code to allow video capture on server \n",
        "\n",
        "TODO: \n",
        "*   Pickle reward, entropy history \n",
        "*   Replace fully connected layer with LSTM? \n",
        "*   Add code to evaluate # of self protective base attacks\n",
        "*   Add code to obfuscate parts of the scene\n",
        "*   Add code to anneal between obfuscated and visible \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfDH4nrQSlnj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7956
        },
        "outputId": "b59a6703-04a0-41fd-a122-ebecd790edb9"
      },
      "source": [
        "# install all the packages\n",
        "!apt-get update\n",
        "!apt-get install -y python-numpy python-dev cmake zlib1g-dev libjpeg-dev xvfb ffmpeg xorg-dev python-opengl libboost-all-dev libsdl2-dev swig\n",
        "!apt-get install python-opengl -y\n",
        "!apt install xvfb -y\n",
        "!pip install gym\n",
        "!pip install \"gym[atari]\"\n",
        "!pip install tqdm\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install piglet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,609 B]\n",
            "Hit:3 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [424 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,190 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [304 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [776 kB]\n",
            "Fetched 2,950 kB in 2s (1,242 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cmake is already the newest version (3.10.2-1ubuntu2).\n",
            "libjpeg-dev is already the newest version (8c-2ubuntu8).\n",
            "libjpeg-dev set to manually installed.\n",
            "python-dev is already the newest version (2.7.15~rc1-1).\n",
            "python-numpy is already the newest version (1:1.13.3-2ubuntu1).\n",
            "python-numpy set to manually installed.\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-0ubuntu2).\n",
            "zlib1g-dev set to manually installed.\n",
            "libboost-all-dev is already the newest version (1.65.1.0ubuntu1).\n",
            "ffmpeg is already the newest version (7:3.4.4-0ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  gir1.2-ibus-1.0 libcapnp-0.6.1 libdbus-1-dev libdmx-dev libdmx1\n",
            "  libfontenc-dev libfs-dev libfs6 libibus-1.0-5 libibus-1.0-dev\n",
            "  libmirclient-dev libmirclient9 libmircommon-dev libmircommon7\n",
            "  libmircookie-dev libmircookie2 libmircore-dev libmircore1 libmirprotobuf3\n",
            "  libpciaccess-dev libpixman-1-dev libprotobuf-dev libprotobuf-lite10\n",
            "  libpulse-dev libpulse-mainloop-glib0 libsndio-dev libudev-dev libxaw7-dev\n",
            "  libxcomposite-dev libxcursor-dev libxfont-dev libxinerama-dev\n",
            "  libxkbcommon-dev libxkbfile-dev libxmuu-dev libxpm-dev libxrandr-dev\n",
            "  libxres-dev libxres1 libxtst-dev libxv-dev libxvmc-dev libxvmc1\n",
            "  libxxf86dga-dev libxxf86dga1 mir-client-platform-mesa-dev swig3.0\n",
            "  x11proto-composite-dev x11proto-dri2-dev x11proto-fonts-dev x11proto-gl-dev\n",
            "  x11proto-randr-dev x11proto-record-dev x11proto-render-dev\n",
            "  x11proto-resource-dev x11proto-xf86bigfont-dev x11proto-xf86dga-dev\n",
            "  x11proto-xinerama-dev xserver-xorg-dev\n",
            "Suggested packages:\n",
            "  libxaw-doc libgle3 swig-doc swig-examples swig3.0-examples swig3.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  gir1.2-ibus-1.0 libcapnp-0.6.1 libdbus-1-dev libdmx-dev libdmx1\n",
            "  libfontenc-dev libfs-dev libfs6 libibus-1.0-5 libibus-1.0-dev\n",
            "  libmirclient-dev libmirclient9 libmircommon-dev libmircommon7\n",
            "  libmircookie-dev libmircookie2 libmircore-dev libmircore1 libmirprotobuf3\n",
            "  libpciaccess-dev libpixman-1-dev libprotobuf-dev libprotobuf-lite10\n",
            "  libpulse-dev libpulse-mainloop-glib0 libsdl2-dev libsndio-dev libudev-dev\n",
            "  libxaw7-dev libxcomposite-dev libxcursor-dev libxfont-dev libxinerama-dev\n",
            "  libxkbcommon-dev libxkbfile-dev libxmuu-dev libxpm-dev libxrandr-dev\n",
            "  libxres-dev libxres1 libxtst-dev libxv-dev libxvmc-dev libxvmc1\n",
            "  libxxf86dga-dev libxxf86dga1 mir-client-platform-mesa-dev python-opengl swig\n",
            "  swig3.0 x11proto-composite-dev x11proto-dri2-dev x11proto-fonts-dev\n",
            "  x11proto-gl-dev x11proto-randr-dev x11proto-record-dev x11proto-render-dev\n",
            "  x11proto-resource-dev x11proto-xf86bigfont-dev x11proto-xf86dga-dev\n",
            "  x11proto-xinerama-dev xorg-dev xserver-xorg-dev xvfb\n",
            "0 upgraded, 64 newly installed, 0 to remove and 58 not upgraded.\n",
            "Need to get 7,598 kB of archives.\n",
            "After this operation, 44.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdmx1 amd64 1:1.1.3-1 [10.4 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libibus-1.0-5 amd64 1.5.17-3ubuntu4 [134 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-ibus-1.0 amd64 1.5.17-3ubuntu4 [66.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcapnp-0.6.1 amd64 0.6.1-1ubuntu1 [658 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdbus-1-dev amd64 1.12.2-1ubuntu1 [165 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdmx-dev amd64 1:1.1.3-1 [34.4 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfontenc-dev amd64 1:1.1.3-1 [13.8 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfs6 amd64 2:1.0.7-1 [22.5 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-fonts-dev all 2018.4-4 [2,620 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfs-dev amd64 2:1.0.7-1 [26.8 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libibus-1.0-dev amd64 1.5.17-3ubuntu4 [145 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircore1 amd64 0.31.1-0ubuntu1 [26.5 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircommon7 amd64 0.31.1-0ubuntu1 [73.9 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotobuf-lite10 amd64 3.0.0-9.1ubuntu1 [97.7 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmirprotobuf3 amd64 0.31.1-0ubuntu1 [127 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmirclient9 amd64 0.31.1-0ubuntu1 [199 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircore-dev amd64 0.31.1-0ubuntu1 [21.7 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotobuf-dev amd64 3.0.0-9.1ubuntu1 [959 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxkbcommon-dev amd64 0.8.0-1ubuntu0.1 [308 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircommon-dev amd64 0.31.1-0ubuntu1 [13.9 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircookie2 amd64 0.31.1-0ubuntu1 [19.7 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircookie-dev amd64 0.31.1-0ubuntu1 [4,392 B]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmirclient-dev amd64 0.31.1-0ubuntu1 [47.8 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpixman-1-dev amd64 0.34.0-2 [244 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpulse-mainloop-glib0 amd64 1:11.1-1ubuntu7.2 [22.1 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpulse-dev amd64 1:11.1-1ubuntu7.2 [81.5 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsndio-dev amd64 1.1.0-3 [13.3 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libudev-dev amd64 237-3ubuntu10.21 [19.1 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcursor-dev amd64 1:1.1.15-1 [26.5 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-xinerama-dev all 2018.4-4 [2,628 B]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxinerama-dev amd64 2:1.1.3-1 [8,404 B]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-randr-dev all 2018.4-4 [2,620 B]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxrandr-dev amd64 2:1.5.1-1 [24.0 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxv-dev amd64 2:1.0.11-1 [32.5 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsdl2-dev amd64 2.0.8+dfsg1-1ubuntu1.18.04.3 [684 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxpm-dev amd64 1:3.5.12-1 [87.4 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxaw7-dev amd64 2:1.0.13-1 [231 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-composite-dev all 1:2018.4-4 [2,620 B]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcomposite-dev amd64 1:0.4.4-2 [9,136 B]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxfont-dev amd64 1:2.0.3-1 [118 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxkbfile-dev amd64 1:1.0.9-2 [74.3 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxmuu-dev amd64 2:1.1.2-2 [7,056 B]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxres1 amd64 2:1.2.0-2 [7,716 B]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-resource-dev all 2018.4-4 [2,620 B]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxres-dev amd64 2:1.2.0-2 [8,136 B]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-record-dev all 2018.4-4 [2,620 B]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxtst-dev amd64 2:1.2.3-1 [15.2 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxvmc1 amd64 2:1.0.10-1 [13.7 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxvmc-dev amd64 2:1.0.10-1 [21.3 kB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-xf86dga-dev all 2018.4-4 [2,624 B]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga-dev amd64 2:1.1.4-1 [17.6 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu bionic/main amd64 mir-client-platform-mesa-dev amd64 0.31.1-0ubuntu1 [11.0 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-dri2-dev all 2018.4-4 [2,620 B]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-gl-dev all 2018.4-4 [2,612 B]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-render-dev all 2:2018.4-4 [2,620 B]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-xf86bigfont-dev all 2018.4-4 [2,628 B]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpciaccess-dev amd64 0.14-1 [20.2 kB]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 xserver-xorg-dev amd64 2:1.19.6-1ubuntu4.2 [199 kB]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 xorg-dev all 1:7.7+19ubuntu7.1 [4,300 B]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.2 [783 kB]\n",
            "Fetched 7,598 kB in 2s (3,417 kB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package libdmx1:amd64.\n",
            "(Reading database ... 130812 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libdmx1_1%3a1.1.3-1_amd64.deb ...\n",
            "Unpacking libdmx1:amd64 (1:1.1.3-1) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../01-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package libibus-1.0-5:amd64.\n",
            "Preparing to unpack .../02-libibus-1.0-5_1.5.17-3ubuntu4_amd64.deb ...\n",
            "Unpacking libibus-1.0-5:amd64 (1.5.17-3ubuntu4) ...\n",
            "Selecting previously unselected package gir1.2-ibus-1.0:amd64.\n",
            "Preparing to unpack .../03-gir1.2-ibus-1.0_1.5.17-3ubuntu4_amd64.deb ...\n",
            "Unpacking gir1.2-ibus-1.0:amd64 (1.5.17-3ubuntu4) ...\n",
            "Selecting previously unselected package libcapnp-0.6.1:amd64.\n",
            "Preparing to unpack .../04-libcapnp-0.6.1_0.6.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcapnp-0.6.1:amd64 (0.6.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libdbus-1-dev:amd64.\n",
            "Preparing to unpack .../05-libdbus-1-dev_1.12.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking libdbus-1-dev:amd64 (1.12.2-1ubuntu1) ...\n",
            "Selecting previously unselected package libdmx-dev:amd64.\n",
            "Preparing to unpack .../06-libdmx-dev_1%3a1.1.3-1_amd64.deb ...\n",
            "Unpacking libdmx-dev:amd64 (1:1.1.3-1) ...\n",
            "Selecting previously unselected package libfontenc-dev:amd64.\n",
            "Preparing to unpack .../07-libfontenc-dev_1%3a1.1.3-1_amd64.deb ...\n",
            "Unpacking libfontenc-dev:amd64 (1:1.1.3-1) ...\n",
            "Selecting previously unselected package libfs6:amd64.\n",
            "Preparing to unpack .../08-libfs6_2%3a1.0.7-1_amd64.deb ...\n",
            "Unpacking libfs6:amd64 (2:1.0.7-1) ...\n",
            "Selecting previously unselected package x11proto-fonts-dev.\n",
            "Preparing to unpack .../09-x11proto-fonts-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-fonts-dev (2018.4-4) ...\n",
            "Selecting previously unselected package libfs-dev:amd64.\n",
            "Preparing to unpack .../10-libfs-dev_2%3a1.0.7-1_amd64.deb ...\n",
            "Unpacking libfs-dev:amd64 (2:1.0.7-1) ...\n",
            "Selecting previously unselected package libibus-1.0-dev:amd64.\n",
            "Preparing to unpack .../11-libibus-1.0-dev_1.5.17-3ubuntu4_amd64.deb ...\n",
            "Unpacking libibus-1.0-dev:amd64 (1.5.17-3ubuntu4) ...\n",
            "Selecting previously unselected package libmircore1:amd64.\n",
            "Preparing to unpack .../12-libmircore1_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmircore1:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libmircommon7:amd64.\n",
            "Preparing to unpack .../13-libmircommon7_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmircommon7:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libprotobuf-lite10:amd64.\n",
            "Preparing to unpack .../14-libprotobuf-lite10_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package libmirprotobuf3:amd64.\n",
            "Preparing to unpack .../15-libmirprotobuf3_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmirprotobuf3:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libmirclient9:amd64.\n",
            "Preparing to unpack .../16-libmirclient9_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmirclient9:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libmircore-dev:amd64.\n",
            "Preparing to unpack .../17-libmircore-dev_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmircore-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libprotobuf-dev:amd64.\n",
            "Preparing to unpack .../18-libprotobuf-dev_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package libxkbcommon-dev.\n",
            "Preparing to unpack .../19-libxkbcommon-dev_0.8.0-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libxkbcommon-dev (0.8.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libmircommon-dev:amd64.\n",
            "Preparing to unpack .../20-libmircommon-dev_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmircommon-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libmircookie2:amd64.\n",
            "Preparing to unpack .../21-libmircookie2_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmircookie2:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libmircookie-dev:amd64.\n",
            "Preparing to unpack .../22-libmircookie-dev_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmircookie-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libmirclient-dev:amd64.\n",
            "Preparing to unpack .../23-libmirclient-dev_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking libmirclient-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package libpixman-1-dev:amd64.\n",
            "Preparing to unpack .../24-libpixman-1-dev_0.34.0-2_amd64.deb ...\n",
            "Unpacking libpixman-1-dev:amd64 (0.34.0-2) ...\n",
            "Selecting previously unselected package libpulse-mainloop-glib0:amd64.\n",
            "Preparing to unpack .../25-libpulse-mainloop-glib0_1%3a11.1-1ubuntu7.2_amd64.deb ...\n",
            "Unpacking libpulse-mainloop-glib0:amd64 (1:11.1-1ubuntu7.2) ...\n",
            "Selecting previously unselected package libpulse-dev:amd64.\n",
            "Preparing to unpack .../26-libpulse-dev_1%3a11.1-1ubuntu7.2_amd64.deb ...\n",
            "Unpacking libpulse-dev:amd64 (1:11.1-1ubuntu7.2) ...\n",
            "Selecting previously unselected package libsndio-dev:amd64.\n",
            "Preparing to unpack .../27-libsndio-dev_1.1.0-3_amd64.deb ...\n",
            "Unpacking libsndio-dev:amd64 (1.1.0-3) ...\n",
            "Selecting previously unselected package libudev-dev:amd64.\n",
            "Preparing to unpack .../28-libudev-dev_237-3ubuntu10.21_amd64.deb ...\n",
            "Unpacking libudev-dev:amd64 (237-3ubuntu10.21) ...\n",
            "Selecting previously unselected package libxcursor-dev:amd64.\n",
            "Preparing to unpack .../29-libxcursor-dev_1%3a1.1.15-1_amd64.deb ...\n",
            "Unpacking libxcursor-dev:amd64 (1:1.1.15-1) ...\n",
            "Selecting previously unselected package x11proto-xinerama-dev.\n",
            "Preparing to unpack .../30-x11proto-xinerama-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-xinerama-dev (2018.4-4) ...\n",
            "Selecting previously unselected package libxinerama-dev:amd64.\n",
            "Preparing to unpack .../31-libxinerama-dev_2%3a1.1.3-1_amd64.deb ...\n",
            "Unpacking libxinerama-dev:amd64 (2:1.1.3-1) ...\n",
            "Selecting previously unselected package x11proto-randr-dev.\n",
            "Preparing to unpack .../32-x11proto-randr-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-randr-dev (2018.4-4) ...\n",
            "Selecting previously unselected package libxrandr-dev:amd64.\n",
            "Preparing to unpack .../33-libxrandr-dev_2%3a1.5.1-1_amd64.deb ...\n",
            "Unpacking libxrandr-dev:amd64 (2:1.5.1-1) ...\n",
            "Selecting previously unselected package libxv-dev:amd64.\n",
            "Preparing to unpack .../34-libxv-dev_2%3a1.0.11-1_amd64.deb ...\n",
            "Unpacking libxv-dev:amd64 (2:1.0.11-1) ...\n",
            "Selecting previously unselected package libsdl2-dev:amd64.\n",
            "Preparing to unpack .../35-libsdl2-dev_2.0.8+dfsg1-1ubuntu1.18.04.3_amd64.deb ...\n",
            "Unpacking libsdl2-dev:amd64 (2.0.8+dfsg1-1ubuntu1.18.04.3) ...\n",
            "Selecting previously unselected package libxpm-dev:amd64.\n",
            "Preparing to unpack .../36-libxpm-dev_1%3a3.5.12-1_amd64.deb ...\n",
            "Unpacking libxpm-dev:amd64 (1:3.5.12-1) ...\n",
            "Selecting previously unselected package libxaw7-dev:amd64.\n",
            "Preparing to unpack .../37-libxaw7-dev_2%3a1.0.13-1_amd64.deb ...\n",
            "Unpacking libxaw7-dev:amd64 (2:1.0.13-1) ...\n",
            "Selecting previously unselected package x11proto-composite-dev.\n",
            "Preparing to unpack .../38-x11proto-composite-dev_1%3a2018.4-4_all.deb ...\n",
            "Unpacking x11proto-composite-dev (1:2018.4-4) ...\n",
            "Selecting previously unselected package libxcomposite-dev:amd64.\n",
            "Preparing to unpack .../39-libxcomposite-dev_1%3a0.4.4-2_amd64.deb ...\n",
            "Unpacking libxcomposite-dev:amd64 (1:0.4.4-2) ...\n",
            "Selecting previously unselected package libxfont-dev.\n",
            "Preparing to unpack .../40-libxfont-dev_1%3a2.0.3-1_amd64.deb ...\n",
            "Unpacking libxfont-dev (1:2.0.3-1) ...\n",
            "Selecting previously unselected package libxkbfile-dev:amd64.\n",
            "Preparing to unpack .../41-libxkbfile-dev_1%3a1.0.9-2_amd64.deb ...\n",
            "Unpacking libxkbfile-dev:amd64 (1:1.0.9-2) ...\n",
            "Selecting previously unselected package libxmuu-dev:amd64.\n",
            "Preparing to unpack .../42-libxmuu-dev_2%3a1.1.2-2_amd64.deb ...\n",
            "Unpacking libxmuu-dev:amd64 (2:1.1.2-2) ...\n",
            "Selecting previously unselected package libxres1:amd64.\n",
            "Preparing to unpack .../43-libxres1_2%3a1.2.0-2_amd64.deb ...\n",
            "Unpacking libxres1:amd64 (2:1.2.0-2) ...\n",
            "Selecting previously unselected package x11proto-resource-dev.\n",
            "Preparing to unpack .../44-x11proto-resource-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-resource-dev (2018.4-4) ...\n",
            "Selecting previously unselected package libxres-dev.\n",
            "Preparing to unpack .../45-libxres-dev_2%3a1.2.0-2_amd64.deb ...\n",
            "Unpacking libxres-dev (2:1.2.0-2) ...\n",
            "Selecting previously unselected package x11proto-record-dev.\n",
            "Preparing to unpack .../46-x11proto-record-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-record-dev (2018.4-4) ...\n",
            "Selecting previously unselected package libxtst-dev:amd64.\n",
            "Preparing to unpack .../47-libxtst-dev_2%3a1.2.3-1_amd64.deb ...\n",
            "Unpacking libxtst-dev:amd64 (2:1.2.3-1) ...\n",
            "Selecting previously unselected package libxvmc1:amd64.\n",
            "Preparing to unpack .../48-libxvmc1_2%3a1.0.10-1_amd64.deb ...\n",
            "Unpacking libxvmc1:amd64 (2:1.0.10-1) ...\n",
            "Selecting previously unselected package libxvmc-dev:amd64.\n",
            "Preparing to unpack .../49-libxvmc-dev_2%3a1.0.10-1_amd64.deb ...\n",
            "Unpacking libxvmc-dev:amd64 (2:1.0.10-1) ...\n",
            "Selecting previously unselected package x11proto-xf86dga-dev.\n",
            "Preparing to unpack .../50-x11proto-xf86dga-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-xf86dga-dev (2018.4-4) ...\n",
            "Selecting previously unselected package libxxf86dga-dev:amd64.\n",
            "Preparing to unpack .../51-libxxf86dga-dev_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga-dev:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package mir-client-platform-mesa-dev:amd64.\n",
            "Preparing to unpack .../52-mir-client-platform-mesa-dev_0.31.1-0ubuntu1_amd64.deb ...\n",
            "Unpacking mir-client-platform-mesa-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Selecting previously unselected package python-opengl.\n",
            "Preparing to unpack .../53-python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Selecting previously unselected package swig3.0.\n",
            "Preparing to unpack .../54-swig3.0_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig3.0 (3.0.12-1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../55-swig_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig (3.0.12-1) ...\n",
            "Selecting previously unselected package x11proto-dri2-dev.\n",
            "Preparing to unpack .../56-x11proto-dri2-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-dri2-dev (2018.4-4) ...\n",
            "Selecting previously unselected package x11proto-gl-dev.\n",
            "Preparing to unpack .../57-x11proto-gl-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-gl-dev (2018.4-4) ...\n",
            "Selecting previously unselected package x11proto-render-dev.\n",
            "Preparing to unpack .../58-x11proto-render-dev_2%3a2018.4-4_all.deb ...\n",
            "Unpacking x11proto-render-dev (2:2018.4-4) ...\n",
            "Selecting previously unselected package x11proto-xf86bigfont-dev.\n",
            "Preparing to unpack .../59-x11proto-xf86bigfont-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-xf86bigfont-dev (2018.4-4) ...\n",
            "Selecting previously unselected package libpciaccess-dev:amd64.\n",
            "Preparing to unpack .../60-libpciaccess-dev_0.14-1_amd64.deb ...\n",
            "Unpacking libpciaccess-dev:amd64 (0.14-1) ...\n",
            "Selecting previously unselected package xserver-xorg-dev.\n",
            "Preparing to unpack .../61-xserver-xorg-dev_2%3a1.19.6-1ubuntu4.2_amd64.deb ...\n",
            "Unpacking xserver-xorg-dev (2:1.19.6-1ubuntu4.2) ...\n",
            "Selecting previously unselected package xorg-dev.\n",
            "Preparing to unpack .../62-xorg-dev_1%3a7.7+19ubuntu7.1_all.deb ...\n",
            "Unpacking xorg-dev (1:7.7+19ubuntu7.1) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../63-xvfb_2%3a1.19.6-1ubuntu4.2_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.2) ...\n",
            "Setting up x11proto-fonts-dev (2018.4-4) ...\n",
            "Setting up x11proto-dri2-dev (2018.4-4) ...\n",
            "Setting up libdbus-1-dev:amd64 (1.12.2-1ubuntu1) ...\n",
            "Setting up libxcursor-dev:amd64 (1:1.1.15-1) ...\n",
            "Setting up libxkbcommon-dev (0.8.0-1ubuntu0.1) ...\n",
            "Setting up libpulse-mainloop-glib0:amd64 (1:11.1-1ubuntu7.2) ...\n",
            "Setting up libpulse-dev:amd64 (1:11.1-1ubuntu7.2) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up swig3.0 (3.0.12-1) ...\n",
            "Setting up libpciaccess-dev:amd64 (0.14-1) ...\n",
            "Setting up libmircore-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libxres1:amd64 (2:1.2.0-2) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.2) ...\n",
            "Setting up libxpm-dev:amd64 (1:3.5.12-1) ...\n",
            "Setting up libsndio-dev:amd64 (1.1.0-3) ...\n",
            "Setting up libxres-dev (2:1.2.0-2) ...\n",
            "Setting up x11proto-xf86bigfont-dev (2018.4-4) ...\n",
            "Setting up libxkbfile-dev:amd64 (1:1.0.9-2) ...\n",
            "Setting up libxvmc1:amd64 (2:1.0.10-1) ...\n",
            "Setting up libxmuu-dev:amd64 (2:1.1.2-2) ...\n",
            "Setting up x11proto-record-dev (2018.4-4) ...\n",
            "Setting up libxtst-dev:amd64 (2:1.2.3-1) ...\n",
            "Setting up libmircookie2:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libfontenc-dev:amd64 (1:1.1.3-1) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up x11proto-xinerama-dev (2018.4-4) ...\n",
            "Setting up libpixman-1-dev:amd64 (0.34.0-2) ...\n",
            "Setting up x11proto-randr-dev (2018.4-4) ...\n",
            "Setting up libxinerama-dev:amd64 (2:1.1.3-1) ...\n",
            "Setting up x11proto-gl-dev (2018.4-4) ...\n",
            "Setting up libxv-dev:amd64 (2:1.0.11-1) ...\n",
            "Setting up libcapnp-0.6.1:amd64 (0.6.1-1ubuntu1) ...\n",
            "Setting up x11proto-resource-dev (2018.4-4) ...\n",
            "Setting up x11proto-xf86dga-dev (2018.4-4) ...\n",
            "Setting up libfs6:amd64 (2:1.0.7-1) ...\n",
            "Setting up libxxf86dga-dev:amd64 (2:1.1.4-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up libibus-1.0-5:amd64 (1.5.17-3ubuntu4) ...\n",
            "Setting up libdmx1:amd64 (1:1.1.3-1) ...\n",
            "Setting up x11proto-render-dev (2:2018.4-4) ...\n",
            "Setting up libmircore1:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up libudev-dev:amd64 (237-3ubuntu10.21) ...\n",
            "Setting up x11proto-composite-dev (1:2018.4-4) ...\n",
            "Setting up gir1.2-ibus-1.0:amd64 (1.5.17-3ubuntu4) ...\n",
            "Setting up swig (3.0.12-1) ...\n",
            "Setting up libxrandr-dev:amd64 (2:1.5.1-1) ...\n",
            "Setting up libxcomposite-dev:amd64 (1:0.4.4-2) ...\n",
            "Setting up libxaw7-dev:amd64 (2:1.0.13-1) ...\n",
            "Setting up libmirprotobuf3:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libdmx-dev:amd64 (1:1.1.3-1) ...\n",
            "Setting up libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up libxvmc-dev:amd64 (2:1.0.10-1) ...\n",
            "Setting up libmircookie-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libxfont-dev (1:2.0.3-1) ...\n",
            "Setting up libibus-1.0-dev:amd64 (1.5.17-3ubuntu4) ...\n",
            "Setting up libfs-dev:amd64 (2:1.0.7-1) ...\n",
            "Setting up libmircommon7:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libmirclient9:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libmircommon-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libmirclient-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up libsdl2-dev:amd64 (2.0.8+dfsg1-1ubuntu1.18.04.3) ...\n",
            "Setting up mir-client-platform-mesa-dev:amd64 (0.31.1-0ubuntu1) ...\n",
            "Setting up xserver-xorg-dev (2:1.19.6-1ubuntu4.2) ...\n",
            "Setting up xorg-dev (1:7.7+19ubuntu7.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-opengl is already the newest version (3.1.0+dfsg-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 58 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 58 not upgraded.\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.10.11)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.16.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.2.1)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (2.21.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (1.24.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (3.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym) (0.16.0)\n",
            "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.6/dist-packages (0.10.11)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.16.3)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.3.2)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.2.1)\n",
            "Requirement already satisfied: atari-py>=0.1.4; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (0.1.7)\n",
            "Requirement already satisfied: PyOpenGL; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (3.1.0)\n",
            "Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (4.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym[atari]) (0.16.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]) (1.24.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]) (3.0.4)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow; extra == \"atari\"->gym[atari]) (0.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading https://files.pythonhosted.org/packages/39/37/f285403a09cc261c56b6574baace1bdcf4b8c7428c8a7239cbba137bc0eb/PyVirtualDisplay-0.2.1.tar.gz\n",
            "Collecting EasyProcess (from pyvirtualdisplay)\n",
            "  Downloading https://files.pythonhosted.org/packages/45/3a/4eecc0c7995a13a64739bbedc0d3691fc574245b7e79cff81905aa0c2b38/EasyProcess-0.2.5.tar.gz\n",
            "Building wheels for collected packages: pyvirtualdisplay, EasyProcess\n",
            "  Building wheel for pyvirtualdisplay (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/8c/16/1c64227974ae29c687e4cc30fd691d5c0fd40f54446dde99da\n",
            "  Building wheel for EasyProcess (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/22/19/af15ef6264c58b625a82641ed7483ad05e258fbd8925505227\n",
            "Successfully built pyvirtualdisplay EasyProcess\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.2.5 pyvirtualdisplay-0.2.1\n",
            "Collecting piglet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/f6/ef278239ebe525466ea51a7dd9d6d3211d197ac4b4abc76e17cdd419f69c/piglet-0.4.4.tar.gz (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.9MB/s \n",
            "\u001b[?25hCollecting Parsley (from piglet)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/d6/4fed8d65e28a970e1c5cb33ce9c7e22e3de745e1b2ae37af051ef16aea3b/Parsley-1.3-py2.py3-none-any.whl (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from piglet) (19.1.0)\n",
            "Collecting astunparse (from piglet)\n",
            "  Downloading https://files.pythonhosted.org/packages/2e/37/5dd0dd89b87bb5f0f32a7e775458412c52d78f230ab8d0c65df6aabc4479/astunparse-1.6.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.6/dist-packages (from piglet) (1.1.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from astunparse->piglet) (1.12.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from astunparse->piglet) (0.33.1)\n",
            "Building wheels for collected packages: piglet\n",
            "  Building wheel for piglet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/59/a5/5bd1a35a4a4596714c4c7925a1751e7b1580b6ced363fd7969\n",
            "Successfully built piglet\n",
            "Installing collected packages: Parsley, astunparse, piglet\n",
            "Successfully installed Parsley-1.3 astunparse-1.6.2 piglet-0.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKg_2u98SqCc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6794a01-2139-4bc3-909a-7ec52ffc9dd5"
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "from __future__ import print_function, division\n",
        "from IPython.core import display\n",
        "from IPython.display import HTML, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gym\n",
        "from PIL import Image, ImageDraw\n",
        "from gym.core import Wrapper\n",
        "from gym.spaces.box import Box\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Conv2D, Dense, Flatten, Input, LSTM, Reshape\n",
        "from keras.models import Model, Sequential\n",
        "from tqdm import trange\n",
        "from google.colab import files\n",
        "import datetime\n",
        "from time import time, sleep, gmtime, strftime\n",
        "import uuid\n",
        "import pickle\n",
        "import random\n",
        "import queue\n",
        "import threading"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh5c3yyTS-K6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# used to enable Tensorboard\n",
        "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip > /dev/null 2>&1\n",
        "! unzip ngrok-stable-linux-amd64.zip > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbA-iTnTTLrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IltkY9gTOYE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1be9a9b0-a63a-4a4a-9d2c-bdbc5d7b5e84"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://494a1f7f.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qHq-WAFTS3R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c070559d-f9ed-4d44-8d7b-de6e86b326c2"
      },
      "source": [
        "# mount Google drive - to store model checkpoints, etc\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMLTH5Fyb21m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.seed(100)\n",
        "\n",
        "# FLAGS\n",
        "T_MAX = 100000000\n",
        "NUM_THREADS = 8\n",
        "INITIAL_LEARNING_RATE = 1e-4\n",
        "DISCOUNT_FACTOR = 0.99\n",
        "VERBOSE_EVERY = 40000\n",
        "TESTING = False\n",
        "\n",
        "I_ASYNC_UPDATE = 5\n",
        "\n",
        "FLAGS = {\"T_MAX\": T_MAX, \"NUM_THREADS\": NUM_THREADS, \"INITIAL_LEARNING_RATE\":\n",
        "INITIAL_LEARNING_RATE, \"DISCOUNT_FACTOR\": DISCOUNT_FACTOR, \"VERBOSE_EVERY\":\n",
        "VERBOSE_EVERY, \"TESTING\": TESTING, \"I_ASYNC_UPDATE\": I_ASYNC_UPDATE}\n",
        "\n",
        "training_finished = False\n",
        "last_T = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW9AKs_lTaQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "if os.environ.get(\"DISPLAY\") is str and len(os.environ.get(\"DISPLAY\"))!=0:\n",
        "    !bash ../xvfb start\n",
        "    %env DISPLAY=:1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Wup_JPyTjlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class CustomGym:\n",
        "#     def __init__(self, game_name, skip_actions=4, num_frames=4, w=64, h=64, crop=lambda img: img):\n",
        "#         self.env = gym.make(game_name)\n",
        "#         self.num_frames = num_frames\n",
        "#         self.skip_actions = skip_actions\n",
        "#         self.w = w\n",
        "#         self.h = h\n",
        "#         self.crop = crop\n",
        "#         if game_name == 'SpaceInvaders-v0':\n",
        "#             self.action_space = [1,2,3] # For space invaders\n",
        "#         elif game_name == 'Pong-v0':\n",
        "#             self.action_space = [1,2,3]\n",
        "#         elif game_name == 'Breakout-v0':\n",
        "#             self.action_space = [1,4,5]\n",
        "#         else:\n",
        "#             # Use the actions specified by Open AI. Sometimes this has more\n",
        "#             # actions than we want, and some actions do the same thing.\n",
        "#             self.action_space = range(env.action_space.n)\n",
        "\n",
        "#         self.action_size = len(self.action_space)\n",
        "#         self.observation_shape = self.env.observation_space.shape\n",
        "\n",
        "#         self.state = None\n",
        "#         self.game_name = game_name\n",
        "\n",
        "#     def preprocess(self, obs, is_start=False):\n",
        "#         obs = self.crop(obs)\n",
        "#         grayscale = obs.astype('float32').mean(2)\n",
        "#         # s = imresize(grayscale, (self.w, self.h)).astype('float32') * (1.0/255.0)\n",
        "#         grayscale = Image.fromarray(grayscale).resize((self.w, self.h))\n",
        "#         s = np.array(grayscale).astype('float32') / 255.\n",
        "#         s = s.reshape(1, s.shape[0], s.shape[1], 1)\n",
        "#         if is_start or self.state is None:\n",
        "#             self.state = np.repeat(s, self.num_frames, axis=3)\n",
        "#         else:\n",
        "#             self.state = np.append(s, self.state[:,:,:,:self.num_frames-1], axis=3)\n",
        "#         return self.state\n",
        "\n",
        "#     def render(self):\n",
        "#         self.env.render()\n",
        "\n",
        "#     def reset(self):\n",
        "#         return self.preprocess(self.env.reset(), is_start=True)\n",
        "\n",
        "#     def step(self, action_idx):\n",
        "#         action = self.action_space[action_idx]\n",
        "#         accum_reward = 0\n",
        "#         prev_s = None\n",
        "#         for _ in range(self.skip_actions):\n",
        "#             s, r, term, info = self.env.step(action)\n",
        "#             accum_reward += r\n",
        "#             if term:\n",
        "#                 break\n",
        "#             prev_s = s\n",
        "#         # Takes maximum value for each pixel value over the current and previous\n",
        "#         # frame. Used to get round Atari sprites flickering (Mnih et al. (2015))\n",
        "#         if self.game_name == 'SpaceInvaders-v0' and prev_s is not None:\n",
        "#             s = np.maximum.reduce([s, prev_s])\n",
        "#         return self.preprocess(s), accum_reward, term, info\n",
        "\n",
        "\n",
        "class CustomGym(Wrapper):\n",
        "    def __init__(self, env, game_name, skip_actions=4, num_frames=4, w=64, h=64, crop=lambda img: img):\n",
        "        \"\"\"A gym wrapper that reshapes, crops and scales image into the desired shapes\"\"\"\n",
        "        super(CustomGym, self).__init__(env)\n",
        "        self.num_frames = num_frames\n",
        "        self.skip_actions = skip_actions\n",
        "        self.w = w\n",
        "        self.h = h\n",
        "        self.crop = crop\n",
        "        if game_name == 'SpaceInvaders-v0':\n",
        "            self.action_space = [1,2,3] # For space invaders\n",
        "        elif game_name == 'Pong-v0':\n",
        "            self.action_space = [1,2,3]\n",
        "        elif game_name == 'Breakout-v0':\n",
        "            self.action_space = [1,4,5]\n",
        "        else:\n",
        "            # Use the actions specified by Open AI. Sometimes this has more\n",
        "            # actions than we want, and some actions do the same thing.\n",
        "            self.action_space = range(env.action_space.n)\n",
        "\n",
        "        self.action_size = len(self.action_space)\n",
        "        self.observation_space = env.observation_space\n",
        "        self.observation_shape = env.observation_space.shape\n",
        "        \n",
        "        self.state = None\n",
        "        self.game_name = game_name\n",
        "\n",
        "    def preprocess(self, obs, is_start=False):\n",
        "        obs = self.crop(obs)\n",
        "        grayscale = obs.astype('float32').mean(2)\n",
        "        # s = imresize(grayscale, (self.w, self.h)).astype('float32') * (1.0/255.0)\n",
        "        grayscale = Image.fromarray(grayscale).resize((self.w, self.h))\n",
        "        s = np.array(grayscale).astype('float32') / 255.\n",
        "        s = s.reshape(1, s.shape[0], s.shape[1], 1)\n",
        "        if is_start or self.state is None:\n",
        "            self.state = np.repeat(s, self.num_frames, axis=3)\n",
        "        else:\n",
        "            self.state = np.append(s, self.state[:,:,:,:self.num_frames-1], axis=3)\n",
        "        return self.state\n",
        "\n",
        "#     def render(self):\n",
        "#         self.env.render()\n",
        "\n",
        "    def reset(self):\n",
        "        return self.preprocess(self.env.reset(), is_start=True)\n",
        "\n",
        "    def step(self, action_idx):\n",
        "        action = self.action_space[action_idx]\n",
        "        accum_reward = 0\n",
        "        prev_s = None\n",
        "        for _ in range(self.skip_actions):\n",
        "            s, r, term, info = self.env.step(action)\n",
        "            accum_reward += r\n",
        "            if term:\n",
        "                break\n",
        "            prev_s = s\n",
        "        # Takes maximum value for each pixel value over the current and previous\n",
        "        # frame. Used to get round Atari sprites flickering (Mnih et al. (2015))\n",
        "        if self.game_name == 'SpaceInvaders-v0' and prev_s is not None:\n",
        "            s = np.maximum.reduce([s, prev_s])\n",
        "        return self.preprocess(s), accum_reward, term, info\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMc3OL2_TtBa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "26119fa4-012c-4e23-eae3-6a07374d3bbb"
      },
      "source": [
        "# env = CustomGym(game_name=\"SpaceInvaders-v0\", crop=lambda img: img[35:-20, :], h=64, w=64)\n",
        "\n",
        "def make_env():\n",
        "    env = gym.make(\"SpaceInvaders-v0\")\n",
        "    env = CustomGym(env, game_name=\"SpaceInvaders-v0\", crop=lambda img: img[35:-20, :], h=64, w=64)\n",
        "    return env\n",
        "\n",
        "env = make_env()\n",
        "\n",
        "obs_shape = env.observation_shape\n",
        "n_actions = env.action_size\n",
        "\n",
        "print(\"Observation shape:\", obs_shape)\n",
        "print(\"Num actions:\", n_actions)\n",
        "print(\"Action names:\", env.env.env.get_action_meanings())\n",
        "print(\"Actions:\", env.action_space)\n",
        "\n",
        "s = env.reset()\n",
        "accum_reward = 0\n",
        "for _ in range(100):\n",
        "    s, reward, _, _ = env.step(random.randint(0,n_actions)-1)\n",
        "    accum_reward += reward\n",
        "\n",
        "plt.title('Game image')\n",
        "plt.imshow(env.render('rgb_array'))\n",
        "plt.show()\n",
        "\n",
        "plt.title('Agent observation (4-frame buffer)')\n",
        "print(s.shape)\n",
        "plt.imshow(s[0].transpose([0,2,1]).reshape([64,-1]))\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation shape: (210, 160, 3)\n",
            "Num actions: 3\n",
            "Action names: ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n",
            "Actions: [1, 2, 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAEICAYAAADBfBG8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(1, 64, 64, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACDCAYAAACdg+BGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoFPST_CUVqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent():\n",
        "    def __init__(self, session, action_size, optimizer=tf.train.AdamOptimizer(INITIAL_LEARNING_RATE)):\n",
        "\n",
        "        self.action_size = action_size\n",
        "        self.optimizer = optimizer\n",
        "        self.sess = session\n",
        "\n",
        "        with tf.variable_scope('network'):\n",
        "            self.action = tf.placeholder('int32', [None], name='action')\n",
        "            self.target_value = tf.placeholder('float32', [None], name='target_value')\n",
        "\n",
        "            self.state, self.policy, self.value = self.build_model(64, 64, 4)\n",
        "            self.weights = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
        "            scope='network')\n",
        "            self.advantages = tf.placeholder('float32', [None], name='advantages')\n",
        "\n",
        "        with tf.variable_scope('optimizer'):\n",
        "            # Compute the one hot vectors for each action given.\n",
        "            action_one_hot = tf.one_hot(self.action, self.action_size, 1.0, 0.0)\n",
        "\n",
        "            # Clipping required to play nice with logs (0,1)\n",
        "            min_policy = 1e-8\n",
        "            max_policy = 1.0 - 1e-8\n",
        "            self.log_policy = tf.log(tf.clip_by_value(self.policy, 0.000001, 0.999999))\n",
        "\n",
        "            # For a given state and action, compute the log of the policy at\n",
        "            # that action for that state. This also works on batches.\n",
        "            self.log_pi_for_action = tf.reduce_sum(tf.multiply(self.log_policy, action_one_hot), reduction_indices=1)\n",
        "\n",
        "            # Takes in R_t - V(s_t) as in the async paper. Note that we feed in\n",
        "            # the advantages so that V(s_t) is treated as a constant for the\n",
        "            # gradient. This is because V(s_t) is the baseline (called 'b' in\n",
        "            # the REINFORCE algorithm). As long as the baseline is constant wrt\n",
        "            # the parameters we are optimising (in this case those for the\n",
        "            # policy), then the expected value of grad_theta log pi * b is zero,\n",
        "            # so the choice of b doesn't affect the expectation. It reduces the\n",
        "            # variance though.\n",
        "            # We want to do gradient ascent on the expected discounted reward.\n",
        "            # The gradient of the expected discounted reward is the gradient of\n",
        "            # log pi * (R - estimated V), where R is the sampled reward from the\n",
        "            # given state following the policy pi. Since we want to maximise\n",
        "            # this, we define the policy loss as the negative and get tensorflow\n",
        "            # to do the automatic differentiation for us.\n",
        "            self.policy_loss = -tf.reduce_mean(self.log_pi_for_action * self.advantages)\n",
        "\n",
        "            # The value loss is much easier to understand: we want our value\n",
        "            # function to accurately estimated the sampled discounted rewards,\n",
        "            # so we just impose a square error loss.\n",
        "            # Note that the target value should be the discounted reward for the\n",
        "            # state as just sampled.\n",
        "            self.value_loss = tf.reduce_mean(tf.square(self.target_value - self.value))\n",
        "\n",
        "            # We follow Mnih's paper and introduce the entropy as another loss\n",
        "            # to the policy. The entropy of a probability distribution is just\n",
        "            # the expected value of - log P(X), denoted E(-log P(X)), which we\n",
        "            # can compute for our policy at any given state with\n",
        "            # sum(policy * -log(policy)), as below. This will be a positive\n",
        "            # number, since self.policy contains numbers between 0 and 1, so the\n",
        "            # log is negative. Note that entropy is smaller when the probability\n",
        "            # distribution is more concentrated on one action, so a larger\n",
        "            # entropy implies more exploration. Thus we penalise small entropy,\n",
        "            # or equivalently, add -entropy to our loss.\n",
        "            self.entropy = tf.reduce_sum(tf.multiply(self.policy, -self.log_policy))\n",
        "\n",
        "            # Try to minimise the loss. There is some rationale for choosing the\n",
        "            # weighted linear combination here that I found somewhere else that\n",
        "            # I can't remember, but I haven't tried to optimise it.\n",
        "            # Note the negative entropy term, which encourages exploration:\n",
        "            # higher entropy corresponds to less certainty.\n",
        "            self.loss = 0.5 * self.value_loss + self.policy_loss - self.entropy\\\n",
        "            * 0.01\n",
        "\n",
        "            # Compute the gradient of the loss with respect to all the weights,\n",
        "            # and create a list of tuples consisting of the gradient to apply to\n",
        "            # the weight.\n",
        "            grads = tf.gradients(self.loss, self.weights)\n",
        "            grads, _ = tf.clip_by_global_norm(grads, 40.0)\n",
        "            grads_vars = list(zip(grads, self.weights))\n",
        "\n",
        "            # Create an operator to apply the gradients using the optimizer.\n",
        "            # Note that apply_gradients is the second part of minimize() for the\n",
        "            # optimizer, so will minimize the loss.\n",
        "            self.train_op = optimizer.apply_gradients(grads_vars)\n",
        "\n",
        "    def get_policy(self, state):\n",
        "        return self.sess.run(self.policy, {self.state: state}).flatten()\n",
        "\n",
        "    def get_value(self, state):\n",
        "        return self.sess.run(self.value, {self.state: state}).flatten()\n",
        "\n",
        "    def get_policy_and_value(self, state):\n",
        "        policy, value = self.sess.run([self.policy, self.value], {self.state:\n",
        "        state})\n",
        "        return policy.flatten(), value.flatten()\n",
        "\n",
        "    # Train the network on the given states and rewards\n",
        "    def train(self, states, actions, target_values, advantages):\n",
        "        # Training\n",
        "        self.sess.run(self.train_op, feed_dict={\n",
        "            self.state: states,\n",
        "            self.action: actions,\n",
        "            self.target_value: target_values,\n",
        "            self.advantages: advantages\n",
        "        })\n",
        "\n",
        "    # Builds the DQN model as in Mnih, but we get a softmax output for the\n",
        "    # policy from fc1 and a linear output for the value from fc1.\n",
        "    def build_model(self, h, w, channels):\n",
        "        self.layers = {}\n",
        "        state = tf.placeholder('float32', shape=(None, h, w, channels), name='state')\n",
        "        self.layers['state'] = state\n",
        "        # First convolutional layer\n",
        "        with tf.variable_scope('conv1', reuse=tf.AUTO_REUSE):\n",
        "            conv1 = tf.contrib.layers.convolution2d(inputs=state,\n",
        "            num_outputs=16, kernel_size=[8,8], stride=[4,4], padding=\"VALID\",\n",
        "            activation_fn=tf.nn.relu,\n",
        "            weights_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
        "            biases_initializer=tf.zeros_initializer())\n",
        "            self.layers['conv1'] = conv1\n",
        "\n",
        "        # Second convolutional layer\n",
        "        with tf.variable_scope('conv2', reuse=tf.AUTO_REUSE):\n",
        "            conv2 = tf.contrib.layers.convolution2d(inputs=conv1, num_outputs=32,\n",
        "            kernel_size=[4,4], stride=[2,2], padding=\"VALID\",\n",
        "            activation_fn=tf.nn.relu,\n",
        "            weights_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
        "            biases_initializer=tf.zeros_initializer())\n",
        "            self.layers['conv2'] = conv2\n",
        "\n",
        "        # Flatten the network\n",
        "        with tf.variable_scope('flatten', reuse=tf.AUTO_REUSE):\n",
        "            flatten = tf.contrib.layers.flatten(inputs=conv2)\n",
        "            self.layers['flatten'] = flatten\n",
        "\n",
        "        # Fully connected layer with 256 hidden units\n",
        "        with tf.variable_scope('fc1', reuse=tf.AUTO_REUSE):\n",
        "            fc1 = tf.contrib.layers.fully_connected(inputs=flatten, num_outputs=256,\n",
        "            activation_fn=tf.nn.relu,\n",
        "            weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
        "            biases_initializer=tf.zeros_initializer())\n",
        "            self.layers['fc1'] = fc1\n",
        "\n",
        "        # The policy output\n",
        "        with tf.variable_scope('policy', reuse=tf.AUTO_REUSE):\n",
        "            policy = tf.contrib.layers.fully_connected(inputs=fc1,\n",
        "            num_outputs=self.action_size, activation_fn=tf.nn.softmax,\n",
        "            weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
        "            biases_initializer=None)\n",
        "            self.layers['policy'] = policy\n",
        "\n",
        "        # The value output\n",
        "        with tf.variable_scope('value', reuse=tf.AUTO_REUSE):\n",
        "            value = tf.contrib.layers.fully_connected(inputs=fc1, num_outputs=1,\n",
        "            activation_fn=None,\n",
        "            weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
        "            biases_initializer=None)\n",
        "            self.layers['value'] = value\n",
        "\n",
        "        return state, policy, value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2hivJjFaJsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Summary:\n",
        "    def __init__(self, logdir, agent):\n",
        "        with tf.variable_scope('summary'):\n",
        "            summarising = ['episode_avg_reward', 'avg_value']\n",
        "            self.agent = agent\n",
        "            self.writer = tf.summary.FileWriter(logdir, self.agent.sess.graph)\n",
        "            self.summary_ops = {}\n",
        "            self.summary_vars = {}\n",
        "            self.summary_ph = {}\n",
        "            for s in summarising:\n",
        "                self.summary_vars[s] = tf.Variable(0.0)\n",
        "                self.summary_ph[s] = tf.placeholder('float32', name=s)\n",
        "                self.summary_ops[s] = tf.summary.scalar(s, self.summary_vars[s])\n",
        "            self.update_ops = []\n",
        "            for k in self.summary_vars:\n",
        "                self.update_ops.append(self.summary_vars[k].assign(self.summary_ph[k]))\n",
        "            self.summary_op = tf.summary.merge(list(self.summary_ops.values()))\n",
        "\n",
        "    def write_summary(self, summary, t):\n",
        "        self.agent.sess.run(self.update_ops, {self.summary_ph[k]: v for k, v in summary.items()})\n",
        "        summary_to_add = self.agent.sess.run(self.summary_op, {self.summary_vars[k]: v for k, v in summary.items()})\n",
        "        self.writer.add_summary(summary_to_add, global_step=t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg56RbPMb-ZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def async_trainer(agent, env, sess, thread_idx, T_queue, summary, saver,\n",
        "    save_path):\n",
        "    print (\"Training thread\", thread_idx)\n",
        "    T = T_queue.get()\n",
        "    T_queue.put(T+1)\n",
        "    t = 0\n",
        "\n",
        "    last_verbose = T\n",
        "    last_time = time()\n",
        "    last_target_update = T\n",
        "\n",
        "    terminal = True\n",
        "    while T < T_MAX:\n",
        "        t_start = t\n",
        "        batch_states = []\n",
        "        batch_rewards = []\n",
        "        batch_actions = []\n",
        "        baseline_values = []\n",
        "\n",
        "        if terminal:\n",
        "            terminal = False\n",
        "            state = env.reset()\n",
        "\n",
        "        while not terminal and len(batch_states) < I_ASYNC_UPDATE:\n",
        "            # Save the current state\n",
        "            batch_states.append(state)\n",
        "\n",
        "            # Choose an action randomly according to the policy\n",
        "            # probabilities. We do this anyway to prevent us having to compute\n",
        "            # the baseline value separately.\n",
        "            policy, value = agent.get_policy_and_value(state)\n",
        "            action_idx = np.random.choice(agent.action_size, p=policy)\n",
        "\n",
        "            # Take the action and get the next state, reward and terminal.\n",
        "            state, reward, terminal, _ = env.step(action_idx)\n",
        "\n",
        "            # Update counters\n",
        "            t += 1\n",
        "            T = T_queue.get()\n",
        "            T_queue.put(T+1)\n",
        "\n",
        "            # Clip the reward to be between -1 and 1\n",
        "            reward = np.clip(reward, -1, 1)\n",
        "\n",
        "            # Save the rewards and actions\n",
        "            batch_rewards.append(reward)\n",
        "            batch_actions.append(action_idx)\n",
        "            baseline_values.append(value[0])\n",
        "\n",
        "        target_value = 0\n",
        "        # If the last state was terminal, just put R = 0. Else we want the\n",
        "        # estimated value of the last state.\n",
        "        if not terminal:\n",
        "            target_value = agent.get_value(state)[0]\n",
        "        last_R = target_value\n",
        "\n",
        "        # Compute the sampled n-step discounted reward\n",
        "        batch_target_values = []\n",
        "        for reward in reversed(batch_rewards):\n",
        "            target_value = reward + DISCOUNT_FACTOR * target_value\n",
        "            batch_target_values.append(target_value)\n",
        "        # Reverse the batch target values, so they are in the correct order\n",
        "        # again.\n",
        "        batch_target_values.reverse()\n",
        "\n",
        "        # Test batch targets\n",
        "        if TESTING:\n",
        "            temp_rewards = batch_rewards + [last_R]\n",
        "            test_batch_target_values = []\n",
        "            for j in range(len(batch_rewards)):\n",
        "                test_batch_target_values.append(discount(temp_rewards[j:], DISCOUNT_FACTOR))\n",
        "            if not test_equals(batch_target_values, test_batch_target_values,\n",
        "                1e-5):\n",
        "                print (\"Assertion failed\")\n",
        "                print (last_R)\n",
        "                print (batch_rewards)\n",
        "                print (batch_target_values)\n",
        "                print (test_batch_target_values)\n",
        "\n",
        "        # Compute the estimated value of each state\n",
        "        batch_advantages = np.array(batch_target_values) - np.array(baseline_values)\n",
        "\n",
        "        # Apply asynchronous gradient update\n",
        "        agent.train(np.vstack(batch_states), batch_actions, batch_target_values,\n",
        "        batch_advantages)\n",
        "\n",
        "    global training_finished\n",
        "    training_finished = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvidhkFpcDvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def estimate_reward(agent, env, episodes=10, max_steps=10000):\n",
        "    episode_rewards = []\n",
        "    episode_vals = []\n",
        "    t = 0\n",
        "    for i in range(episodes):\n",
        "        episode_reward = 0\n",
        "        state = env.reset()\n",
        "        terminal = False\n",
        "        while not terminal:\n",
        "            policy, value = agent.get_policy_and_value(state)\n",
        "            action_idx = np.random.choice(agent.action_size, p=policy)\n",
        "            state, reward, terminal, _ = env.step(action_idx)\n",
        "            t += 1\n",
        "            episode_vals.append(value)\n",
        "            episode_reward += reward\n",
        "            if t > max_steps:\n",
        "                episode_rewards.append(episode_reward)\n",
        "                return episode_rewards, episode_vals\n",
        "        episode_rewards.append(episode_reward)\n",
        "    return episode_rewards, episode_vals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7RPavlTcHC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluator(agent, env, sess, T_queue, summary, saver, save_path):\n",
        "    # Read T and put the same T back on.\n",
        "    T = T_queue.get()\n",
        "    T_queue.put(T)\n",
        "    last_time = time()\n",
        "    last_verbose = T\n",
        "    \n",
        "    rewards_history = []\n",
        "    \n",
        "    while T < T_MAX:\n",
        "        T = T_queue.get()\n",
        "        T_queue.put(T)\n",
        "        if T - last_verbose >= VERBOSE_EVERY:\n",
        "            print (\"T\", T)\n",
        "            current_time = time()\n",
        "            print (\"Train steps per second\", float(T - last_verbose) / (current_time - last_time))\n",
        "            last_time = current_time\n",
        "            last_verbose = T\n",
        "\n",
        "            print (\"Evaluating agent\")\n",
        "            episode_rewards, episode_vals = estimate_reward(agent, env, episodes=5)\n",
        "            avg_ep_r = np.mean(episode_rewards)\n",
        "            avg_val = np.mean(episode_vals)\n",
        "            print (\"Avg ep reward\", avg_ep_r, \"Average value\", avg_val)\n",
        "            \n",
        "            rewards_history.append(avg_ep_r)\n",
        "            \n",
        "            # Plot the rewards as we go\n",
        "            clear_output(True)\n",
        "            plt.figure(figsize=[8,4])\n",
        "            plt.subplot(1,2,1)\n",
        "            plt.plot(rewards_history, label='rewards')\n",
        "            plt.plot(pd.DataFrame(np.array(rewards_history)).ewm(span=10).mean(), marker='.', label='rewards ewma@10')\n",
        "            plt.title(\"Session rewards\"); plt.grid(); plt.legend()\n",
        "            plt.show()\n",
        "        \n",
        "            global last_T\n",
        "            last_t = T\n",
        "            \n",
        "            # also write to Tensorboard\n",
        "            summary.write_summary({'episode_avg_reward': avg_ep_r, 'avg_value': avg_val}, T)\n",
        "            checkpoint_file = saver.save(sess, save_path, global_step=T)\n",
        "            print (\"Saved in\", checkpoint_file)\n",
        "            \n",
        "            pickle.dump( episode_rewards , open( save_path + \"_rewards\", \"wb\" ) )\n",
        "            pickle.dump( episode_vals , open( save_path + \"_value\", \"wb\" ) )\n",
        "        sleep(1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SmuIRKgcJtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def a3c(game_name, num_threads=8, restore=None, save_path='model'):\n",
        "    processes = []\n",
        "    envs = []\n",
        "    \n",
        "    # create num_threads + 1 environments \n",
        "    for _ in range(num_threads+1):\n",
        "        gym_env = gym.make(game_name)\n",
        "        print (\"Assuming ATARI game and playing with pixels\")\n",
        "        env = make_env()\n",
        "        envs.append(env)\n",
        "\n",
        "    # Separate out the evaluation environment\n",
        "    evaluation_env = envs[0]\n",
        "    envs = envs[1:]\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        agent = Agent(session=sess,\n",
        "        action_size=envs[0].action_size,\n",
        "        optimizer=tf.train.AdamOptimizer(INITIAL_LEARNING_RATE))\n",
        "\n",
        "        # Create a saver, and only keep 2 checkpoints.\n",
        "        saver = tf.train.Saver(max_to_keep=2)\n",
        "\n",
        "        T_queue = queue.Queue()\n",
        "\n",
        "        # Either restore the parameters or don't.\n",
        "        if restore is not None:\n",
        "            saver.restore(sess, save_path + '-' + str(restore))\n",
        "            last_T = restore\n",
        "            print (\"T was:\", last_T)\n",
        "            T_queue.put(last_T)\n",
        "        else:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            T_queue.put(0)\n",
        "\n",
        "        summary = Summary(LOG_DIR, agent)\n",
        "\n",
        "        # Create a process for each worker\n",
        "        for i in range(num_threads):\n",
        "            processes.append(threading.Thread(target=async_trainer, args=(agent,\n",
        "            envs[i], sess, i, T_queue, summary, saver, save_path,)))\n",
        "\n",
        "        # Create a process to evaluate the agent\n",
        "        processes.append(threading.Thread(target=evaluator, args=(agent,\n",
        "        evaluation_env, sess, T_queue, summary, saver, save_path,)))\n",
        "\n",
        "        # Start all the processes\n",
        "        for p in processes:\n",
        "            p.daemon = True\n",
        "            p.start()\n",
        "\n",
        "        # Until training is finished\n",
        "        while not training_finished:\n",
        "            sleep(0.01)\n",
        "\n",
        "        # Join the processes, so we get this thread back.\n",
        "        for p in processes:\n",
        "            p.join()\n",
        "\n",
        "# Returns sum(rewards[i] * gamma**i)\n",
        "def discount(rewards, gamma):\n",
        "    return np.sum([rewards[i] * gamma**i for i in range(len(rewards))])\n",
        "\n",
        "def test_equals(arr1, arr2, eps):\n",
        "    return np.sum(np.abs(np.array(arr1)-np.array(arr2))) < eps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiXwzmqTfFnp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13fecdec-3f9f-497a-cf5e-61ed37cef31c"
      },
      "source": [
        "model_id = model_id = str(datetime.date.today()) + \"-\" + str(uuid.uuid1())\n",
        "print(model_id)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-05-04-5a0c38bc-6e9b-11e9-9454-0242ac1c0002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKgoMWxDcSBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "f6442884-29b4-405b-a354-c0fa7474f946"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "save_path = F\"/content/gdrive/My Drive/RL_models/\" + model_id\n",
        "restore = None\n",
        "game_name = \"SpaceInvaders-v0\"\n",
        "\n",
        "reward_history = []\n",
        "\n",
        "a3c(game_name, num_threads=NUM_THREADS, restore=None,\n",
        "    save_path=save_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Assuming ATARI game and playing with pixels\n",
            "Assuming ATARI game and playing with pixels\n",
            "Assuming ATARI game and playing with pixels\n",
            "Assuming ATARI game and playing with pixels\n",
            "Assuming ATARI game and playing with pixels\n",
            "Assuming ATARI game and playing with pixels\n",
            "Assuming ATARI game and playing with pixels\n",
            "Assuming ATARI game and playing with pixels\n",
            "Assuming ATARI game and playing with pixels\n",
            "Training thread 0\n",
            "Training thread 1\n",
            "Training thread 2\n",
            "Training thread 3\n",
            "Training thread 4\n",
            "Training thread 5\n",
            "Training thread 6\n",
            "Training thread 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvWiWrgYceCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def play(agent, game_name, num_episodes=10, fps=5.0, monitor=True):\n",
        "#     gym_env = gym.make(game_name)\n",
        "#     if monitor:\n",
        "#         print(gym_env)\n",
        "#         gym_env = gym.wrappers.Monitor(gym_env, directory=\"SI_videos\", video_callable=lambda episode_id: True, force=True)\n",
        "#     print (gym_env)\n",
        "#     print(game_name)\n",
        "    env = make_env()\n",
        "    env = gym.wrappers.Monitor(env, directory=\"SI_videos\", video_callable=lambda episode_id: True, force=True)\n",
        "\n",
        "    desired_frame_length = 1.0 / fps\n",
        "\n",
        "    episode_rewards = []\n",
        "    episode_vals = []\n",
        "    t = 0\n",
        "    for ep in range(num_episodes):\n",
        "        print (\"Starting episode\", ep)\n",
        "        episode_reward = 0\n",
        "        state = env.reset()\n",
        "        print (state.shape)\n",
        "        terminal = False\n",
        "        current_time = time()\n",
        "        while not terminal:\n",
        "            policy, value = agent.get_policy_and_value(state)\n",
        "            action_idx = np.random.choice(agent.action_size, p=policy)\n",
        "            state, reward, terminal, _ = env.step(action_idx)\n",
        "            t += 1\n",
        "            episode_vals.append(value)\n",
        "            episode_reward += reward\n",
        "            # Sleep so the frame rate is correct\n",
        "            next_time = time()\n",
        "            frame_length = next_time - current_time\n",
        "            if frame_length < desired_frame_length:\n",
        "                sleep(desired_frame_length - frame_length)\n",
        "            current_time = next_time\n",
        "        episode_rewards.append(episode_reward)\n",
        "    return episode_rewards, episode_vals\n",
        "\n",
        "def run_agent(save_path, T, game_name):\n",
        "    with tf.Session() as sess:\n",
        "        agent = Agent(session=sess,\n",
        "        action_size=3,\n",
        "        optimizer=tf.train.AdamOptimizer(1e-4))\n",
        "\n",
        "        # Create a saver, and restore checkpoint.\n",
        "        saver = tf.train.Saver()\n",
        "        saver.restore(sess, save_path + '-' + str(T))\n",
        "\n",
        "        episode_rewards, episode_vals = play(agent, game_name, num_episodes=2)\n",
        "\n",
        "        return sess, agent, episode_rewards, episode_vals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CTKCW7NhZIn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d83b50a7-552b-4ce2-af1b-fc0acc3a9df1"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "# call to run the agent \n",
        "print (last_T)\n",
        "s, a, e_r, e_v = run_agent(F\"/content/gdrive/My Drive/RL_models/\" + \"2019-05-03-506b9b98-6de4-11e9-ae34-0242ac1c0002\", 280797, game_name)\n",
        "print (e_r)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/RL_models/2019-05-03-506b9b98-6de4-11e9-ae34-0242ac1c0002-280797\n",
            "Starting episode 0\n",
            "(1, 64, 64, 4)\n",
            "Starting episode 1\n",
            "(1, 64, 64, 4)\n",
            "[110.0, 50.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8d0dRJKs6EO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e88863be-f162-4611-88c2-645180a289d0"
      },
      "source": [
        "video_names = list(filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./SI_videos/\")))\n",
        "print(video_names)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['openaigym.video.15.14956.video000001.mp4', 'openaigym.video.15.14956.video000000.mp4']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "108V3ApTCVSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('./SI_videos/openaigym.video.15.14956.video000001.mp4')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}